{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "local-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../pipelines/esg_trending_topics/transform.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# ~------------------ RESPONSE DATA ------------------~\n",
    "def process_response(response, kw, ranking, geo):\n",
    "    \"\"\" Utility function for create_response_df() \"\"\"\n",
    "    try:\n",
    "        df = response[kw][ranking]\n",
    "        df[['keyword', 'ranking', 'geo', 'query_timestamp']] = [kw, ranking, geo, datetime.now()]\n",
    "    except:\n",
    "        print(f\"Append empty dataframe for {ranking}: {kw}\")\n",
    "        return pd.DataFrame(columns=['query', 'value', 'keyword', 'ranking', 'geo', 'query_timestamp'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_response_df(response, geo='global'):\n",
    "    \"\"\" Unpack response and create one dataframe for each ranking and each keyword \"\"\"\n",
    "    assert isinstance(response, dict), \"Empty response, caught in transform.py. Try again.\" \n",
    "\n",
    "    ranking = [*response[[*response][0]]]\n",
    "    keywords = [*response]\n",
    "\n",
    "    df_list = []\n",
    "    for r in ranking: \n",
    "        for kw in keywords:\n",
    "            df_list.append(process_response(response, kw=kw, ranking=r, geo=geo))\n",
    "\n",
    "    return pd.concat(df_list)\n",
    "\n",
    "def clean_data(df, blacklist):\n",
    "    \"\"\" Cleans the data\n",
    "            1. drops non-english strings\n",
    "            2. removes entries from blacklist\n",
    "            3. reset index\n",
    "    \n",
    "    Args\n",
    "        df: pd.dataframe, \n",
    "        blacklist: list, contains keywords that should be removed\n",
    "        \n",
    "    Return\n",
    "        dataframe\n",
    "    \"\"\"\n",
    "    # remove non-ascii strings: select rows where string has ascii format  \n",
    "    df_en = df.loc[df['query'].apply(lambda x: x.isascii()), :]\n",
    "\n",
    "    # remove blacklisted words \n",
    "    blacklist = ['esg gold', 'esg glas']\n",
    "    df_clean = df_en.loc[~df_en['query'].str.contains('|'.join(blacklist)),:]\n",
    "    \n",
    "    # reset index\n",
    "    df = df_clean.reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ~------------------ PLOT DATA ------------------~\n",
    "def add_features(df):\n",
    "    \"\"\" Create normalized values for even display \"\"\"\n",
    "    \n",
    "    assert set([\"query\", \"value\", \"keyword\", \"ranking\", \"query_timestamp\", \"geo\"]).issubset(df.columns), \"Add features failed. \\\n",
    "    Missing one of [query, value, keyword, ranking, query_timestamp, geo]\"\n",
    "    \n",
    "    # feature engineering: totals and normalize\n",
    "    grouped = df.groupby(['ranking']).value # group values by ranking\n",
    "    df['value_total'] = grouped.transform('sum') # total sum \n",
    "    df['value_normalized'] = ((df.value-grouped.transform('min'))/(grouped.transform('max')-grouped.transform('min'))).astype(float) \n",
    "    df['value_normalized_total'] = df.groupby(['ranking']).value_normalized.transform('sum') # total sum of normalized values \n",
    "    df['date'] = pd.to_datetime(df.query_timestamp).dt.strftime(\"%d. %B %Y\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def select_topn(df, top_n):\n",
    "    \"\"\" Select top-n keywords for each ranking ordered by value \"\"\"\n",
    "    assert df.columns.str.contains(\"ranking\").any(), \"select_topn failed. Missing 'ranking' column.\"\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.value = pd.to_numeric(df.value, errors='coerce') # avoid object dtype\n",
    "    topn_idx = df.groupby(\"ranking\")['value'].nlargest(top_n).droplevel(0).index\n",
    "\n",
    "    return df.loc[topn_idx, : ]\n",
    "\n",
    "def sanitize_labels(df):\n",
    "    \"\"\" Insert linebreaks and create headings \"\"\"\n",
    "    df['labels'] = df['query'].apply(lambda x: x.replace(' ', '<br>')) # linebreaks\n",
    "    df['ranking_label'] = df.ranking.replace({'top': f'Evergreens - updated {df.date.to_list()[0]}',\n",
    "                                              'rising': f'Trending - updated {df.date.to_list()[0]}'})\n",
    "   \n",
    "    return df\n",
    "\n",
    "def plot_data(df, top_n=35):\n",
    "    \"\"\" Return 2 dataframes: Newcomer (\"rising\") and top charts (\"top\") \"\"\"\n",
    "    df = (df.pipe(select_topn, top_n)\n",
    "            .pipe(add_features)\n",
    "            .pipe(sanitize_labels)\n",
    "            )\n",
    "\n",
    "    # rankings: top and rising    \n",
    "    return df.query('ranking == \"rising\"'),  df.query('ranking == \"top\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-fusion",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-summer",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brilliant-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../pipelines/esg_trending_topics/extract.py\n",
    "import pandas as pd\n",
    "from pytrends.request import TrendReq\n",
    "\n",
    "# ~------------------ EXTRACT ------------------~\n",
    "def get_queries(kw_list):\n",
    "    \"\"\" Calls pytrend' related_queries with a list of keywords and geo settings \n",
    "    Input\n",
    "        pytrend: TrendReq() session of pytrend\n",
    "        kw_list: list of strings, used as input for query and passed to TrendReq().build_payload() \n",
    "    Return\n",
    "        Dataframe with query result\n",
    "    \"\"\"    \n",
    "    assert isinstance(kw_list, list), \"Keyword(s) should be a list\"\n",
    "\n",
    "    df_related_queries = pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        pytrend = TrendReq() \n",
    "\n",
    "        pytrend.build_payload(kw_list)\n",
    "        df_related_queries = pytrend.related_queries()\n",
    "\n",
    "        print(f\"Query succeeded for\", *kw_list, sep='\\n\\t')\n",
    "    except Exception as e:\n",
    "        print(e, \"\\nQuery not unsuccessful. Return empty DataFrame.\\n\", '='*42)\n",
    "\n",
    "    return df_related_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "worse-mandate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query succeeded for\n",
      "\tsustainable investment\n",
      "\tESG\n",
      "\tsustainable finance\n",
      "\tresponsible investment\n"
     ]
    }
   ],
   "source": [
    "df_related_queries = get_queries([\"sustainable investment\", \"ESG\", \"sustainable finance\", \"responsible investment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-alloy",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "about-pizza",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../pipelines/esg_trending_topics/transform.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../pipelines/esg_trending_topics/transform.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# ~------------------ RESPONSE DATA ------------------~\n",
    "def process_response(response, kw, ranking, geo):\n",
    "    \"\"\" Utility function for create_response_df() \"\"\"\n",
    "    try:\n",
    "        df = response[kw][ranking]\n",
    "        df[['keyword', 'ranking', 'geo', 'query_timestamp']] = [kw, ranking, geo, datetime.now()]\n",
    "    except:\n",
    "        print(f\"Append empty dataframe for {ranking}: {kw}\")\n",
    "        return pd.DataFrame(columns=['query', 'value', 'keyword', 'ranking', 'geo', 'query_timestamp'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_response_df(response, geo='global'):\n",
    "    \"\"\" Unpack response and create one dataframe for each ranking and each keyword \"\"\"\n",
    "    assert isinstance(response, dict), \"Empty response, caught in transform.py. Try again.\" \n",
    "\n",
    "    ranking = [*response[[*response][0]]]\n",
    "    keywords = [*response]\n",
    "\n",
    "    df_list = []\n",
    "    for r in ranking: \n",
    "        for kw in keywords:\n",
    "            df_list.append(process_response(response, kw=kw, ranking=r, geo=geo))\n",
    "\n",
    "    return pd.concat(df_list)\n",
    "\n",
    "def clean_data(df, blacklist):\n",
    "    \"\"\" Cleans the data\n",
    "            1. drops non-english strings\n",
    "            2. removes entries from blacklist\n",
    "            3. reset index\n",
    "    \n",
    "    Args\n",
    "        df: pd.dataframe, \n",
    "        blacklist: list, contains keywords that should be removed\n",
    "        \n",
    "    Return\n",
    "        dataframe\n",
    "    \"\"\"\n",
    "    # remove non-ascii strings: select rows where string has ascii format  \n",
    "    df_en = df.loc[df['query'].apply(lambda x: x.isascii()), :]\n",
    "\n",
    "    # remove blacklisted words \n",
    "    blacklist = ['esg gold', 'esg glas']\n",
    "    df_clean = df_en.loc[~df_en['query'].str.contains('|'.join(blacklist)),:]\n",
    "    \n",
    "    # reset index\n",
    "    df = df_clean.reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ~------------------ PLOT DATA ------------------~\n",
    "def add_features(df):\n",
    "    \"\"\" Create normalized values for even display \"\"\"\n",
    "    \n",
    "    assert set([\"query\", \"value\", \"keyword\", \"ranking\", \"query_timestamp\", \"geo\"]).issubset(df.columns), \"Add features failed. \\\n",
    "    Missing one of [query, value, keyword, ranking, query_timestamp, geo]\"\n",
    "    \n",
    "    # feature engineering: totals and normalize\n",
    "    grouped = df.groupby(['ranking']).value # group values by ranking\n",
    "    df['value_total'] = grouped.transform('sum') # total sum \n",
    "    df['value_normalized'] = ((df.value-grouped.transform('min'))/(grouped.transform('max')-grouped.transform('min'))).astype(float) \n",
    "    df['value_normalized_total'] = df.groupby(['ranking']).value_normalized.transform('sum') # total sum of normalized values \n",
    "    df['date'] = pd.to_datetime(df.query_timestamp).dt.strftime(\"%d. %B %Y\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def select_topn(df, top_n):\n",
    "    \"\"\" Select top-n keywords for each ranking ordered by value \"\"\"\n",
    "    assert df.columns.str.contains(\"ranking\").any(), \"select_topn failed. Missing 'ranking' column.\"\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.value = pd.to_numeric(df.value, errors='coerce') # avoid object dtype\n",
    "    topn_idx = df.groupby(\"ranking\")['value'].nlargest(top_n).droplevel(0).index\n",
    "\n",
    "    return df.loc[topn_idx, : ]\n",
    "\n",
    "def sanitize_labels(df, to_uppercase=['ESG']):\n",
    "    \"\"\" Insert linebreaks and create headings \"\"\"\n",
    "    # make some labels uppercase\n",
    "    for s in to_uppercase:\n",
    "        df['query'] = df['query'].str.replace(s.lower(), s)\n",
    "    # create labels\n",
    "    df['labels'] = df['query'].apply(lambda x: x.replace(' ', '<br>')) # linebreaks\n",
    "    df['ranking_label'] = df.ranking.replace({'top': f'Evergreens - updated {df.date.to_list()[0]}',\n",
    "                                              'rising': f'Trending - updated {df.date.to_list()[0]}'})\n",
    "   \n",
    "    return df\n",
    "\n",
    "def plot_data(df, top_n=35):\n",
    "    \"\"\" Return 2 dataframes: Newcomer (\"rising\") and top charts (\"top\") \"\"\"\n",
    "    df = (df.pipe(select_topn, top_n)\n",
    "            .pipe(add_features)\n",
    "            .pipe(sanitize_labels)\n",
    "            )\n",
    "\n",
    "    # rankings: top and rising    \n",
    "    return df.query('ranking == \"rising\"'),  df.query('ranking == \"top\"')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
